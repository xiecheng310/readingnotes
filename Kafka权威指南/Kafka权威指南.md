## 第01章：初始Kafka

### 1.1 发布订阅系统

### 1.2 Kafka简介

#### 1.2.1 消息和批次

- 消息

可以看成数据库的一行记录. 由字节数组组成, 没有特别的格式要求

- 批次

同Partition和Totic的消息, 被批量写入. 减少网络和磁盘IO

#### 1.2.2 模式Schema

即一个schema. 或者说是消息的序列化方式. 很好的解决了消息读写的解耦. 
读写采用相同的数据格式, 就不会因为发布者升级, 订阅者被迫一起升级的问题

#### 1.2.3  主题和分区

- 主题

主题可以看成是数据库的表. 同一类的消息, 投放到同一个Topic中. 主题是一种逻辑分类的概念.

- 分区

如果把主题看做数据库的表, 那他一定是个分区表. 而分区就是这个分区表的每一部分;
他是物理存在的, 可以分布式的置于不同的机器上.所以一个Topic, 是可以跨多个服务器的.

- 关于顺序性

Kafka的消息写入是通过追加日志的方式写入分区.然后以先入先出的方式读取.
如果一个Topic包含多个分区,无法保证整个Topic的消费顺序性.但是在单个Partition中. 消息是顺序被读取的

#### 1.2.4 生产者和消费者

- 生产者

正常情况将消息均匀的写到Topic的每个Partition上. 
但在某些特性场合, 可以通过消息键和分区器将消息写到特定的Partition. 分区器为消息键产生一个散列值, 并映射到指定分区.

- 消费者

可以订阅一个或者多个主题. 并按消息生成的顺序读取. 他是通过偏移量来区分Partition提交的日志中, 哪些已经读取
偏移量相当于Partition的一个指针,不断递增. 消费者读取日志后, 修改偏移量, 并将其值保存在ZK中.所以就算消费者关闭或重启,他的读取状态不会丢失

- 消费者群组

往往消费者会有多个. 但是一个Partition, 只能被一个消费者读取. 这种方式可以增加Kafka整体的吞吐量
就算有一个消费者宕机, 其他消费者可以来接管这个Partition
消费者数量 <= Partition数量. 

#### 1.2.5 Broker和集群

- broker

独立的kafka服务器就是一个broker
broker接受生产者写入消息, 设置偏移量, 持久化消息到磁盘，同时给消费者响应, 返回磁盘上的消息

- broker集群

一个集群, 会有一个Broker被选举为集群控制器: 分配partition给broker以及监控broker
如果一个partition分配给了多个broker, 将发生分区复制, 提供数据冗余, 保证高可用
一旦作为领导的broker宕机, 会从集群中重新选举新的master. 相关的生产者和消费者需要重新连接到新的master

- 关于消息保留

定期保留: 比如保留7天或者12小时
指定大小保留: 当消息达到指定容量, 旧消息就会被过期删除
每个Topic可以定义自己的保存策略

#### 1.2.6 多集群

kafak机器太多, 一个集群无法满足需求, 这就需要多个数据中心，但是分区复制只能在单个集群中进行, 无法在集群间进行数据同步。kafka提供了MirrorMaker工具, 用于集群间消息复制

### 1.3 为什么选择Kafka

#### 1.3.1 多生产者

不论单个还是多个Topic. 多个生产者提供相同格式的数据到指定Topic. 可以聚合多个微服务的信息. 提供统一的数据出口

#### 1.3.2 多消费者

支持多个消费者从一个消息流(Topic)读取消息. 相互不影响. 其实是一种订阅模式. 多个消费者都可以收到这个消息。也支持多消费者组成的群组去共享一个消息流. 一个消息只会被群组中一个消费者消费到。

#### 1.3.3 基于磁盘的数据存储

消息是通过日志的方式追加到partition中. 通过偏移量保存消费者的读取记录。消息提交到磁盘的时候, kafka根据保留规则进行保留.这些消息被持久化到磁盘中
当消费者消费能力减弱, 或者流量突然达峰值, 甚至消费者宕机重启. 都无需担心消息丢失. 因为kafka持久化了消息, 并且保存了消费者上次读取的进度

#### 1.3.4 伸缩性

大规模broker的扩展并不会影响kafka集群的可用性。要提高集群的容错能力，可以配置较高的复制系数

#### 1.3.5 高性能

通过横向扩展生产者、消费者和broker。 Kafka可以轻松处理巨大的消息流， 关键是在处理大量数据的同时，还能保证亚秒级的消息延迟

### 1.4 数据生态系统

Kafka为数据生态系统带来循环，定义标准输入和输出。各个系统不再有紧密耦合。基础生态图例如下：

![image-20200324145947807](C:\Users\Donavon\AppData\Roaming\Typora\typora-user-images\image-20200324145947807.png)

Kafka常用的使用场景有以下：

- 活动跟踪

记录用户在前端页面的访问操作。发布到后端，生成报告，可以为机器学习提供数据，更新搜索结果等

- 传递消息

即作为MQ使用

- 度量指标和日志记录

收集应用程序的指标或日志，用于监控或告警系统。还可以配合Hadoop离线计算，数据分析。

- 提交日志

将数据库更新发布到Kafka上，应用程序通过监听消息流来同步这些数据到其他系统。这样的方式为变更日志提供了缓冲区。如果消费者故障，可以通过日志重放来恢复。

- 流处理

这个功能与Hadoop里面的map和reduce类似，不过Kafka的流处理是实时的。

------

## 第02章：安装Kafka